{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b980808-3a5a-43c6-aef7-828298effd64",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to load the shoreline files, create shoreline segements and transects, and save the data for further processing in nb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fc8c8-7473-410d-a812-8de8d1c724a1",
   "metadata": {},
   "source": [
    "The data is output as a json file (dictionary), where the key is (location, proxy, islet_id, start_date, end_date), where the shoreline change is calculated as a change between the end and start dates.\n",
    "Dates are represented in decimal years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a10297",
   "metadata": {},
   "source": [
    "All the shoreline change values are calculated with respect to the first year in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abaad99",
   "metadata": {},
   "source": [
    "# File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e0e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "import itertools\n",
    "import shapely \n",
    "from shapely.geometry import LineString, shape\n",
    "# from scipy import interpolate\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import pickle\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c749c-a370-441b-bf1f-d4ccc5fd5947",
   "metadata": {},
   "source": [
    "# Load Dataset and Transform Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89cf080-dd95-4344-8714-01649e68ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoll_name = 'Nanumea'\n",
    "proxy = 'WM'\n",
    "intial_epsg_code = 'EPSG:32760'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977533ff-1603-4ec2-b4d8-f342fe7dd9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load file (designed for geojsons produced by CoastSat)\n",
    "geojson_file = \"Preprocessed_datasets/target_file.geojson\"\n",
    "gdf_shoreline = gpd.read_file(geojson_file)\n",
    "\n",
    "# Formatting\n",
    "gdf_shoreline['layer'] = ['Nanumea_TOB_'+str(x).split('-')[0] for x in gdf_shoreline['date']]\n",
    "\n",
    "# Tuvalu data from SPC has id numbers for different atolls.\n",
    "# If dataset has more than one islet, you can manually define which rows pertain to which islet,\n",
    "# then the code will treat them separately thereafter\n",
    "gdf_shoreline['id'] = 1\n",
    "\n",
    "gdf_shoreline['year'] = [x.year for x in gdf_shoreline.date]\n",
    "\n",
    "def multipoint_to_linestring(multipoint):\n",
    "    ''' Helper function for converting multipoints (output from CoastSat) to a linestring '''\n",
    "    return LineString(multipoint.geoms)\n",
    "    \n",
    "gdf_shoreline['geometry'] = gdf_shoreline['geometry'].apply(multipoint_to_linestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b68539-1db5-4a35-9529-1188ca62d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert coordinates\n",
    "transformer = \\\n",
    "    pyproj.Transformer.from_crs(pyproj.CRS(\"EPSG:32760\"),pyproj.CRS(\"EPSG:4326\")) \n",
    "\n",
    "gdf_shoreline['geometry'] = [LineString([transformer.transform(y,x) for x,y in geo.coords]) for geo in gdf_shoreline.geometry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc857215-5507-42a9-88d8-ad2f4d4951bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>satname</th>\n",
       "      <th>geoaccuracy</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>geometry</th>\n",
       "      <th>layer</th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-05-19 22:10:40</td>\n",
       "      <td>L7</td>\n",
       "      <td>5.065</td>\n",
       "      <td>0.022809</td>\n",
       "      <td>LINESTRING (-65.239 150.088, -65.239 150.087, ...</td>\n",
       "      <td>Nanumea_TOB_2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-30 22:10:30</td>\n",
       "      <td>L7</td>\n",
       "      <td>5.787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LINESTRING (-65.239 150.087, -65.239 150.087, ...</td>\n",
       "      <td>Nanumea_TOB_2003</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-03 22:23:36</td>\n",
       "      <td>L8</td>\n",
       "      <td>7.148</td>\n",
       "      <td>0.095328</td>\n",
       "      <td>LINESTRING (-65.234 150.076, -65.234 150.076, ...</td>\n",
       "      <td>Nanumea_TOB_2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-20 22:23:07</td>\n",
       "      <td>L8</td>\n",
       "      <td>7.566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LINESTRING (-65.211 150.003, -65.211 150.003, ...</td>\n",
       "      <td>Nanumea_TOB_2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-03-09 22:22:32</td>\n",
       "      <td>L8</td>\n",
       "      <td>8.448</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>LINESTRING (-65.239 150.087, -65.239 150.087, ...</td>\n",
       "      <td>Nanumea_TOB_2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2023-12-05 22:37:43</td>\n",
       "      <td>S2</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>LINESTRING (-65.210 150.003, -65.210 150.003, ...</td>\n",
       "      <td>Nanumea_TOB_2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2023-12-07 22:22:11</td>\n",
       "      <td>L9</td>\n",
       "      <td>7.724</td>\n",
       "      <td>0.027839</td>\n",
       "      <td>LINESTRING (-65.239 150.087, -65.239 150.087, ...</td>\n",
       "      <td>Nanumea_TOB_2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2023-12-15 22:37:42</td>\n",
       "      <td>S2</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>0.117506</td>\n",
       "      <td>LINESTRING (-65.235 150.065, -65.235 150.065, ...</td>\n",
       "      <td>Nanumea_TOB_2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2023-12-23 22:22:19</td>\n",
       "      <td>L9</td>\n",
       "      <td>6.601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LINESTRING (-65.239 150.087, -65.239 150.087, ...</td>\n",
       "      <td>Nanumea_TOB_2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2023-12-30 22:37:48</td>\n",
       "      <td>S2</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>LINESTRING (-65.231 150.044, -65.231 150.044, ...</td>\n",
       "      <td>Nanumea_TOB_2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date satname geoaccuracy  cloud_cover  \\\n",
       "0   2002-05-19 22:10:40      L7       5.065     0.022809   \n",
       "1   2003-01-30 22:10:30      L7       5.787     0.000000   \n",
       "2   2013-12-03 22:23:36      L8       7.148     0.095328   \n",
       "3   2014-01-20 22:23:07      L8       7.566     0.000000   \n",
       "4   2014-03-09 22:22:32      L8       8.448     0.035028   \n",
       "..                  ...     ...         ...          ...   \n",
       "180 2023-12-05 22:37:43      S2      PASSED     0.002276   \n",
       "181 2023-12-07 22:22:11      L9       7.724     0.027839   \n",
       "182 2023-12-15 22:37:42      S2      PASSED     0.117506   \n",
       "183 2023-12-23 22:22:19      L9       6.601     0.000000   \n",
       "184 2023-12-30 22:37:48      S2      PASSED     0.007585   \n",
       "\n",
       "                                              geometry             layer  id  \\\n",
       "0    LINESTRING (-65.239 150.088, -65.239 150.087, ...  Nanumea_TOB_2002   1   \n",
       "1    LINESTRING (-65.239 150.087, -65.239 150.087, ...  Nanumea_TOB_2003   1   \n",
       "2    LINESTRING (-65.234 150.076, -65.234 150.076, ...  Nanumea_TOB_2013   1   \n",
       "3    LINESTRING (-65.211 150.003, -65.211 150.003, ...  Nanumea_TOB_2014   1   \n",
       "4    LINESTRING (-65.239 150.087, -65.239 150.087, ...  Nanumea_TOB_2014   1   \n",
       "..                                                 ...               ...  ..   \n",
       "180  LINESTRING (-65.210 150.003, -65.210 150.003, ...  Nanumea_TOB_2023   1   \n",
       "181  LINESTRING (-65.239 150.087, -65.239 150.087, ...  Nanumea_TOB_2023   1   \n",
       "182  LINESTRING (-65.235 150.065, -65.235 150.065, ...  Nanumea_TOB_2023   1   \n",
       "183  LINESTRING (-65.239 150.087, -65.239 150.087, ...  Nanumea_TOB_2023   1   \n",
       "184  LINESTRING (-65.231 150.044, -65.231 150.044, ...  Nanumea_TOB_2023   1   \n",
       "\n",
       "     year  \n",
       "0    2002  \n",
       "1    2003  \n",
       "2    2013  \n",
       "3    2014  \n",
       "4    2014  \n",
       "..    ...  \n",
       "180  2023  \n",
       "181  2023  \n",
       "182  2023  \n",
       "183  2023  \n",
       "184  2023  \n",
       "\n",
       "[185 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values in the 'geometry' column look coorect for WGS 84\n",
    "gdf_shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de84a73-96ea-4933-8790-4bd236c48754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of dates for future reference\n",
    "dates_dict = {(int(x.year)+(int(x.month)-0.5)/12):datetime.datetime(int(x.year),int(x.month),int(x.day)) for x in gdf_shoreline.date}\n",
    "with open('dates_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(dates_dict, f)\n",
    "\n",
    "geopandas_dict = {\n",
    "        (atoll_name,proxy):gdf_shoreline\n",
    "    }\n",
    "\n",
    "combinations = list(geopandas_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af4afe",
   "metadata": {},
   "source": [
    "# Load the Tuvalu shoreline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a878cc-9f3f-478b-aab7-95cc9640391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 is only needed if you're reading the SPC satellite image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99eb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data using geopandas\n",
    "# base_dir = os.getcwd()\n",
    "\n",
    "# proxies = [\n",
    "#     # r'TOB',\n",
    "#     # r'VL',\n",
    "#     r'WM'\n",
    "# ]\n",
    "\n",
    "# atolls = [\n",
    "#     'Nanumea',\n",
    "#     # 'Nanumanga'\n",
    "# ]\n",
    "\n",
    "# combinations = list(itertools.product(atolls,proxies))\n",
    "\n",
    "# # Define the years the shoreline change datafile is for. This is atoll specific\n",
    "# years_dict = {\n",
    "#     'Nanumea':'2003_2021'\n",
    "# }\n",
    "\n",
    "# geopandas_dict = {}\n",
    "\n",
    "# # There is one shape file per proxy, per year, per atoll\n",
    "# for combination in combinations:\n",
    "#     atoll = combination[0]\n",
    "#     proxy = combination[1]\n",
    "#     year = years_dict[combination[0]]\n",
    "#     gdf_shoreline = gpd.read_file(base_dir+'/Preprocessed_datasets/Shoreline_shapefiles/{}/{}_{}_{}.shp'.format(proxy,atoll,proxy,year)).rename(columns={'Layer':'layer','Area':'area','Perimeter':'perimeter'})\n",
    "    \n",
    "#     geopandas_dict.update({\n",
    "#         (atoll,proxy):gdf_shoreline\n",
    "#     })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ba3ce",
   "metadata": {},
   "source": [
    "# Format Shoreline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7e029b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting the geopandas dataframes into a pandas dataframe\n",
    "# reformat spc satellite images (formatting inconsistencies)\n",
    "### uncomment code for reformatting spc data\n",
    "# Convert gis file formats to shoreline segments\n",
    "\n",
    "# Number of sgements to divide the island into (equal length)\n",
    "total_number_of_line_segments = 200\n",
    "\n",
    "segmented_shoreline_dict = {}\n",
    "\n",
    "# Loop over all dictionary of all geopandas dataframes\n",
    "for key,item in geopandas_dict.items():\n",
    "    atoll = key[0]\n",
    "    proxy = key[1]\n",
    "    \n",
    "    gdf_shoreline = item.copy()\n",
    "\n",
    "    gdf_shoreline['layer'] = gdf_shoreline['layer'].fillna(value=1)\n",
    "    gdf_shoreline['id'] = gdf_shoreline['id'].fillna(value=1)\n",
    "    gdf_shoreline['id'] = gdf_shoreline.id.astype(int)\n",
    "    gdf_shoreline = gdf_shoreline[~gdf_shoreline[['layer','geometry']].isna().any(axis=1)]\n",
    "    \n",
    "    # # There are some typos/inconsistencies in the Tuvalu data which need to be corrected/accounted for\n",
    "    # gdf_shoreline.loc[gdf_shoreline.layer=='Nanumea_WM_2015_','layer'] = 'Nanumea_WM_2015'\n",
    "\n",
    "    # # Some years are formatted differently\n",
    "    # gdf_right_years_dict = {}\n",
    "    # for layer,group in gdf_shoreline.groupby('layer'):\n",
    "    #     if (proxy=='VL')&(atoll!='Nanumaga'):\n",
    "    #         year = int(layer.split('_')[1])\n",
    "    #     else:\n",
    "    #         year = int(layer.split('_')[-1])\n",
    "\n",
    "    #     gdf_right_years_dict.update({\n",
    "    #         year:group\n",
    "    #     })\n",
    "\n",
    "    # gdf_shoreline = pd.concat(gdf_right_years_dict)\n",
    "    # gdf_shoreline.reset_index(drop=False,inplace=True)\n",
    "    \n",
    "    # gdf_shoreline['level_0'] = gdf_shoreline.level_0.astype(int)\n",
    "    # gdf_shoreline['id'] = gdf_shoreline.id.astype(int)\n",
    "    # gdf_shoreline = gdf_shoreline.rename(columns={'level_0':'year'}).drop('level_1',axis=1)\n",
    "    \n",
    "    # # NB: ids 1 and 3 in the wrong way for one year in raw data\n",
    "    # if (atoll=='Nanumea')&(proxy=='TOB'):\n",
    "    #     gdf_shoreline.loc[gdf_shoreline.year==2009,'id'] = gdf_shoreline.loc[gdf_shoreline.year==2009,'id'].replace(1,1000)\n",
    "    #     gdf_shoreline.loc[gdf_shoreline.year==2009,'id'] = gdf_shoreline.loc[gdf_shoreline.year==2009,'id'].replace(3,1)\n",
    "    #     gdf_shoreline.loc[gdf_shoreline.year==2009,'id'] = gdf_shoreline.loc[gdf_shoreline.year==2009,'id'].replace(1000,3)\n",
    "        \n",
    "\n",
    "    # Convert polygons to linestrings if there are any (for Tuvalu satellite data from spc)\n",
    "    # if type(gdf_shoreline.loc[0,'geometry'])==shapely.geometry.Polygon:\n",
    "    #     gdf_shoreline['geometry'] = [x.boundary for x in gdf_shoreline.geometry]\n",
    "        \n",
    "    # Interpolate the linestrings so that they are all of the same length (x)\n",
    "    x = total_number_of_line_segments #number of points to interpolate\n",
    "    for i in np.arange(0,len(gdf_shoreline),1):\n",
    "        gdf_shoreline.loc[i,'geometry'] = \\\n",
    "            shapely.geometry.linestring.LineString(\n",
    "                [gdf_shoreline.loc[i,'geometry'].interpolate((j/x), normalized=True) for j in range(1, x)]\n",
    "            )\n",
    "\n",
    "    dict_of_df_xy = {}\n",
    "    \n",
    "    # Format the coordinates, and put into a pandas dataframe\n",
    "    for idx,row in gdf_shoreline.iterrows():\n",
    "        linestring = row.geometry\n",
    "        XY_list = []\n",
    "        \n",
    "        if type(linestring)==shapely.geometry.linestring.LineString:\n",
    "            XY_list = XY_list+[(x,y) for x,y in linestring.coords]\n",
    "        elif type(linestring)==shapely.geometry.multilinestring.MultiLineString:\n",
    "            XY_list = XY_list+[(x,y) for x,y in linestring[0].coords]\n",
    "                \n",
    "        df_xy = pd.DataFrame(XY_list)\n",
    "        df_xy.columns = ['lon','lat']\n",
    "        df_xy['id'] = int(row.id)\n",
    "        df_xy['year'] = row.year+(int(row.date.month)-0.5)/12#int(row.year) #year column now is a decimal\n",
    "        \n",
    "        dict_of_df_xy.update({\n",
    "            idx:df_xy\n",
    "        })\n",
    "\n",
    "    df_xy = pd.concat(dict_of_df_xy)\n",
    "\n",
    "    # Format new pandas dataframe\n",
    "    df_xy = df_xy.reset_index(drop=True)\n",
    "    df_xy['x'] = df_xy.lon\n",
    "    df_xy['y'] = df_xy.lat\n",
    "    \n",
    "    df_xy[('lon,lat')] = [transformer.transform(x,y) for x,y in zip(df_xy.lon,df_xy.lat)]\n",
    "    df_xy['lon'] = [x[1] for x in df_xy[('lon,lat')]]\n",
    "    df_xy['lat'] = [x[0] for x in df_xy[('lon,lat')]]\n",
    "    \n",
    "    segmented_shoreline_dict.update({\n",
    "        (atoll,proxy):{\n",
    "            'df_xy':df_xy,\n",
    "            'gdf_shoreline':gdf_shoreline\n",
    "        }\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab308f5",
   "metadata": {},
   "source": [
    "# Creating Transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401a027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shoreline_df(df_xy):\n",
    "    ''' Define x and y points at each side the the straight shoreline segment'''\n",
    "    df_temp = pd.concat([df_xy[~df_xy.index.isin(list(df_xy.head(1).index))],df_xy[df_xy.index.isin(list(df_xy.head(1).index))]])\n",
    "\n",
    "    df_shoreline = pd.DataFrame({'x':df_xy.x,\n",
    "                                 'x+n':list(df_temp.x),\n",
    "                                 'y':df_xy.y,\n",
    "                                 'y+n':list(df_temp.y),\n",
    "                                 'lon':df_xy.lon,\n",
    "                                 'lat':df_xy.lat})\n",
    "\n",
    "    # Calculate the gradient of the line between the two shoreline points\n",
    "    df_shoreline['m_shoreline'] = (df_shoreline['y']-df_shoreline['y+n'])/(df_shoreline['x']-df_shoreline['x+n'])\n",
    "    df_shoreline.dropna(axis=0,inplace=True)\n",
    "    df_shoreline = df_shoreline[(df_shoreline['x']-df_shoreline['x+n'])!=0]\n",
    "\n",
    "    # Find the inverse of the gradient (because we are wanting the line that is perpendicular to the shoreline)\n",
    "    df_shoreline['m_transect'] = -df_shoreline['m_shoreline']**-1\n",
    "\n",
    "    df_shoreline['x_avg'] = [x/2 for x in (df_shoreline['x']+df_shoreline['x+n'])]\n",
    "    df_shoreline['y_avg'] = [y/2 for y in (df_shoreline['y']+df_shoreline['y+n'])]\n",
    "\n",
    "    df_shoreline['c_shoreline'] = df_shoreline['y_avg']-df_shoreline['m_shoreline']*df_shoreline['x_avg']\n",
    "    df_shoreline['c_transect'] = df_shoreline['y_avg']-df_shoreline['m_transect']*df_shoreline['x_avg']\n",
    "\n",
    "    H = 1000 # length of the transect line\n",
    "    df_shoreline['delta_y'] = [abs(H*math.sin(math.atan(m))) for m in df_shoreline['m_transect']]\n",
    "    df_shoreline['delta_x'] = [abs(H*math.cos(math.atan(m))) for m in df_shoreline['m_transect']]\n",
    "    \n",
    "    df_shoreline = df_shoreline[df_shoreline.m_shoreline!=0]\n",
    "    \n",
    "    coords_dict = {}\n",
    "    for index,row in df_shoreline.iterrows():\n",
    "        \n",
    "        if (row.y<row['y+n'])&(row.m_shoreline>0):\n",
    "            coords_dict.update({\n",
    "                index:{\n",
    "                'x_new':row.x_avg-row.delta_x,\n",
    "                'y_new':row.y_avg+row.delta_y\n",
    "                }\n",
    "            })\n",
    "        elif (row.y>row['y+n'])&(row.m_shoreline>0):\n",
    "            coords_dict.update({\n",
    "                index:{\n",
    "                'x_new':row.x_avg+row.delta_x,\n",
    "                'y_new':row.y_avg-row.delta_y\n",
    "                }\n",
    "            })\n",
    "        elif (row.y>row['y+n'])&(row.m_shoreline<0):\n",
    "            coords_dict.update({\n",
    "                index:{\n",
    "                'x_new':row.x_avg+row.delta_x,\n",
    "                'y_new':row.y_avg+row.delta_y\n",
    "                }\n",
    "            })\n",
    "        elif (row.y<row['y+n'])&(row.m_shoreline<0):\n",
    "            coords_dict.update({\n",
    "                index:{\n",
    "                'x_new':row.x_avg-row.delta_x,\n",
    "                'y_new':row.y_avg-row.delta_y\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            asdf\n",
    "        \n",
    "    df_coords = pd.DataFrame.from_dict(coords_dict,orient='index')\n",
    "    df_shoreline = df_shoreline.join(df_coords)\n",
    "\n",
    "    return(df_shoreline)\n",
    "\n",
    "\n",
    "def calc_shoreline_change(df_shoreline_1,df_shoreline_2):\n",
    "    '''\n",
    "        Function for finding shoreline change between two years\n",
    "    '''\n",
    "    ### Now you need to find the distance between the two shorelines using the transects\n",
    "    shoreline_2_updated_dict = {}\n",
    "\n",
    "    # loop over each transect\n",
    "    for idx,row in df_shoreline_2.iterrows():\n",
    "        \n",
    "        df_intersection = df_shoreline_1.copy()\n",
    "        \n",
    "        df_intersection['x_intersect_location'] = (df_intersection.c_shoreline-row.c_transect)/(row.m_transect-df_intersection.m_shoreline)\n",
    "        df_intersection['y_intersect_location'] = row['m_transect']*df_intersection['x_intersect_location']+row['c_transect']\n",
    "        df_intersection['intersect_distance'] = np.sqrt((df_intersection['y_intersect_location']-row['y_avg'])**2+\\\n",
    "        (df_intersection['x_intersect_location']-row['x_avg'])**2)\n",
    "\n",
    "        # Find which shoreline segments would intersect with the shoreline\n",
    "        df_intersection = df_intersection[[(x<x_int)&(x_n>x_int)|(x>x_int)&(x_n<x_int)for x,x_int,x_n in zip(df_intersection.x,df_intersection.x_intersect_location,df_intersection['x+n'])]]\n",
    "        df_intersection = df_intersection[[(y<y_int)&(y_n>y_int)|(y>y_int)&(y_n<y_int) for y,y_int,y_n in zip(df_intersection.y,df_intersection.y_intersect_location,df_intersection['y+n'])]]\n",
    "#         There may be multiple, so find the closest one (that *should* be the right one)\n",
    "        \n",
    "        try:\n",
    "            df_intersection = df_intersection[(df_intersection['intersect_distance']==np.min(df_intersection['intersect_distance']))]\n",
    "            intersect_distance = df_intersection.intersect_distance.reset_index(drop=True)[0]\n",
    "            outside = (((df_intersection.x_intersect_location<row.x_avg)&(row.x_new<df_intersection.x_intersect_location))|\\\n",
    "((df_intersection.x_intersect_location>row.x_avg)&(row.x_new>df_intersection.x_intersect_location))).reset_index(drop=True)[0]\n",
    "            if outside:\n",
    "                intersect_distance = -intersect_distance\n",
    "        except:\n",
    "            intersect_distance = 0\n",
    "            \n",
    "        row['intersect_distance'] = intersect_distance\n",
    "        \n",
    "        shoreline_2_updated_dict.update({\n",
    "            idx:row\n",
    "        })\n",
    "\n",
    "    df_shoreline_2 = pd.DataFrame.from_dict(shoreline_2_updated_dict,orient='index')\n",
    "\n",
    "    df_shoreline_2['transect_angle'] = \\\n",
    "        np.arctan((df_shoreline_2.y_new-df_shoreline_2.y_avg)/(df_shoreline_2.x_new-df_shoreline_2.x_avg))*180/np.pi\n",
    "\n",
    "    return(df_shoreline_2)\n",
    "\n",
    "\n",
    "def calc_shoreline_slope_change(df_shoreline):\n",
    "    '''\n",
    "        Calc the direction the shoreline is facing\n",
    "    '''\n",
    "    \n",
    "    df_shoreline = pd.concat([df_shoreline,df_shoreline])\n",
    "\n",
    "    df_shoreline = df_shoreline.reset_index(drop=True)\n",
    "\n",
    "    df_shoreline_dict = {}\n",
    "\n",
    "    for (idx_1,row_1),(idx_2,row_2),(idx_3,row_3) in zip(\n",
    "        df_shoreline[4:].iterrows(),\n",
    "        df_shoreline[2:-2].iterrows(),\n",
    "        df_shoreline[:-4].iterrows()):\n",
    "        \n",
    "        row_2['avg_slope_change'] = np.mean([\n",
    "            (180*np.arctan((row_1.m_shoreline-row_2.m_shoreline)/(1+row_1.m_shoreline*row_2.m_shoreline))/np.pi),\n",
    "            (180*np.arctan((row_2.m_shoreline-row_3.m_shoreline)/(1+row_2.m_shoreline*row_3.m_shoreline))/np.pi)\n",
    "        ])\n",
    "\n",
    "        df_shoreline_dict.update({\n",
    "            idx_2:row_2\n",
    "        })\n",
    "\n",
    "    # only look at points where there is a significant change\n",
    "    df_shoreline = pd.DataFrame.from_dict(df_shoreline_dict,orient='index')\n",
    "    \n",
    "    # Drop the duplicates\n",
    "    df_shoreline = df_shoreline.drop_duplicates()\n",
    "    df_shoreline.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #### Now also add in the angle (degrees) that the shoreline is facing\n",
    "    # Quadrant 1\n",
    "    df_shoreline.loc[(df_shoreline.x_new>df_shoreline.x_avg)&(df_shoreline.y_new>df_shoreline.y_avg),'shoreline_direction']=\\\n",
    "        [180*math.atan(np.abs(x_new-x_avg)/np.abs(y_new-y_avg))/np.pi for y_new,y_avg,x_new,x_avg in zip(\n",
    "                df_shoreline.y_new,\n",
    "                df_shoreline.y_avg,\n",
    "                df_shoreline.x_new,\n",
    "                df_shoreline.x_avg\n",
    "                ) if (x_new>x_avg)&(y_new>y_avg)]\n",
    "\n",
    "    # Quadrant 2\n",
    "    df_shoreline.loc[(df_shoreline.x_new>df_shoreline.x_avg)&(df_shoreline.y_new<df_shoreline.y_avg),'shoreline_direction']=\\\n",
    "        [90+180*math.atan(np.abs(y_new-y_avg)/np.abs(x_new-x_avg))/np.pi for y_new,y_avg,x_new,x_avg in zip(\n",
    "                df_shoreline.y_new,\n",
    "                df_shoreline.y_avg,\n",
    "                df_shoreline.x_new,\n",
    "                df_shoreline.x_avg\n",
    "                ) if (x_new>x_avg)&(y_new<y_avg)]\n",
    "\n",
    "    # Quadrant 3\n",
    "    df_shoreline.loc[(df_shoreline.x_new<df_shoreline.x_avg)&(df_shoreline.y_new<df_shoreline.y_avg),'shoreline_direction']=\\\n",
    "        [180+180*math.atan(np.abs(x_new-x_avg)/np.abs(y_new-y_avg))/np.pi for y_new,y_avg,x_new,x_avg in zip(\n",
    "                df_shoreline.y_new,\n",
    "                df_shoreline.y_avg,\n",
    "                df_shoreline.x_new,\n",
    "                df_shoreline.x_avg\n",
    "                ) if (x_new<x_avg)&(y_new<y_avg)]\n",
    "\n",
    "    # Quadrant 4\n",
    "    df_shoreline.loc[(df_shoreline.x_new<df_shoreline.x_avg)&(df_shoreline.y_new>df_shoreline.y_avg),'shoreline_direction']=\\\n",
    "        [270+180*math.atan(np.abs(y_new-y_avg)/np.abs(x_new-x_avg))/np.pi for y_new,y_avg,x_new,x_avg in zip(\n",
    "                df_shoreline.y_new,\n",
    "                df_shoreline.y_avg,\n",
    "                df_shoreline.x_new,\n",
    "                df_shoreline.x_avg\n",
    "                ) if (x_new<x_avg)&(y_new>y_avg)]\n",
    "\n",
    "    return(df_shoreline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62328b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nanumea', 'WM', 1, 2002.375, 2003.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2013.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2014.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.125)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2015.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2016.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2016.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2016.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2016.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2017.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2017.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2017.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2017.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2018.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2018.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2018.4583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2018.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.125)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2019.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.125)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.4583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2020.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.4583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2021.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.125)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.4583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.875)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2022.9583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.0416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.125)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.2083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.2916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.375)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.4583333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.5416666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.625)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.7083333333333)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.7916666666667)\n",
      "('Nanumea', 'WM', 1, 2002.375, 2023.9583333333333)\n"
     ]
    }
   ],
   "source": [
    "# For each year, proxy and islet combination, run functions above to calc shoreline change\n",
    "shorelines_dict = {}\n",
    "\n",
    "# Each combination of atoll and proxy combination\n",
    "for key,item in segmented_shoreline_dict.items():\n",
    "    df_xy = item['df_xy']\n",
    "    gdf_xy = item['gdf_shoreline']\n",
    "    \n",
    "    # Now get all the ids for this atoll\n",
    "    ids = np.unique(df_xy.id)\n",
    "    \n",
    "    for ID in ids:\n",
    "        df_xy_islet = df_xy[df_xy.id==ID]\n",
    "        gdf_xy_islet = gdf_xy[gdf_xy.id==ID]\n",
    "            \n",
    "        # Get all the years\n",
    "        years = np.sort(np.unique(df_xy_islet.year))\n",
    "        years_beginning = years[:-1]\n",
    "        years_end = years[1:]\n",
    "        \n",
    "        # Loop over the years, defining the beginning and the end year\n",
    "        for year_end in years[1:]:\n",
    "            \n",
    "            df_xy_islet_beginning = df_xy_islet[(df_xy_islet.year==years[0])]\n",
    "            df_xy_islet_end = df_xy_islet[(df_xy_islet.year==year_end)]\n",
    "            \n",
    "            df_shoreline_1 = create_shoreline_df(df_xy_islet_beginning).reset_index(drop=True)\n",
    "            df_shoreline_2 = create_shoreline_df(df_xy_islet_end).reset_index(drop=True)\n",
    "\n",
    "            df_shoreline_2 = calc_shoreline_change(df_shoreline_1,df_shoreline_2)\n",
    "\n",
    "            df_shoreline_2 = calc_shoreline_slope_change(df_shoreline_2)\n",
    "            \n",
    "            # Adding in the final year of the shoreline change dictionary\n",
    "            df_shoreline_2['year1'] = years[0]\n",
    "            df_shoreline_2['year2'] = year_end\n",
    "            \n",
    "            # Filter out the anomalies of anything greater than 100 m change\n",
    "            df_shoreline_2 = df_shoreline_2[np.abs(df_shoreline_2.intersect_distance)<100]\n",
    "            \n",
    "            shorelines_dict.update({\n",
    "                (key[0],key[1],ID,years[0],year_end):df_shoreline_2.to_dict()\n",
    "            })\n",
    "            print((key[0],key[1],ID,years[0],year_end))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab215baa",
   "metadata": {},
   "source": [
    "# Saved the Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ffcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data_and_output/shorelines_dict.json','wb') as fp:\n",
    "    pickle.dump(shorelines_dict,fp)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.984px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
